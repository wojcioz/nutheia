module {
  tt.func public @_chunked_cross_entropy_forward_0d1d2d3d4d(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg1: i32 {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg4: !tt.ptr<i64> {tt.divisibility = 16 : i32}) attributes {noinline = false} {
    %cst = arith.constant dense<0xFF80> : tensor<65536xbf16>
    %cst_0 = arith.constant 0.000000e+00 : f32
    %cst_1 = arith.constant -1.000000e+00 : f32
    %c-100_i32 = arith.constant -100 : i32
    %c0_i32 = arith.constant 0 : i32
    %cst_2 = arith.constant dense<128256> : tensor<65536xi32>
    %c65536_i32 = arith.constant 65536 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = tt.get_program_id x : i32
    %1 = tt.get_program_id y : i32
    %2 = arith.extsi %arg1 : i32 to i64
    %3 = arith.extsi %0 : i32 to i64
    %4 = arith.muli %3, %2 : i64
    %5 = tt.addptr %arg0, %4 : !tt.ptr<bf16>, i64
    %6 = tt.addptr %arg2, %0 : !tt.ptr<f32>, i32
    %7 = arith.muli %0, %c2_i32 : i32
    %8 = arith.addi %7, %1 : i32
    %9 = tt.addptr %arg3, %8 : !tt.ptr<f32>, i32
    %10 = tt.addptr %arg4, %0 : !tt.ptr<i64>, i32
    %11 = arith.muli %1, %c65536_i32 : i32
    %12 = tt.make_range {end = 65536 : i32, start = 0 : i32} : tensor<65536xi32>
    %13 = tt.splat %11 : (i32) -> tensor<65536xi32>
    %14 = arith.addi %13, %12 : tensor<65536xi32>
    %15 = arith.cmpi slt, %14, %cst_2 : tensor<65536xi32>
    %16 = tt.load %10 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : i64
    %17 = arith.trunci %16 : i64 to i32
    %18 = tt.splat %5 : (!tt.ptr<bf16>) -> tensor<65536x!tt.ptr<bf16>>
    %19 = tt.addptr %18, %14 : tensor<65536x!tt.ptr<bf16>>, tensor<65536xi32>
    %20 = tt.load %19, %15, %cst {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : tensor<65536xbf16>
    %21 = arith.extf %20 : tensor<65536xbf16> to tensor<65536xf32>
    %22 = "tt.reduce"(%21) <{axis = 0 : i32}> ({
    ^bb0(%arg5: f32, %arg6: f32):
      %30 = tt.pure_extern_elementwise %arg5, %arg6 {libname = "libdevice", libpath = "/opt/conda/lib/python3.11/site-packages/triton/language/../third_party/cuda/lib/libdevice.10.bc", symbol = "__nv_fmaxf"} : (f32, f32) -> f32
      tt.reduce.return %30 : f32
    }) : (tensor<65536xf32>) -> f32
    %23 = tt.splat %22 : (f32) -> tensor<65536xf32>
    %24 = arith.subf %21, %23 : tensor<65536xf32>
    %25 = math.exp %24 : tensor<65536xf32>
    %26 = "tt.reduce"(%25) <{axis = 0 : i32}> ({
    ^bb0(%arg5: f32, %arg6: f32):
      %30 = arith.addf %arg5, %arg6 : f32
      tt.reduce.return %30 : f32
    }) : (tensor<65536xf32>) -> f32
    %27 = math.log %26 : f32
    %28 = arith.addf %22, %27 : f32
    %29 = arith.cmpi eq, %1, %c0_i32 : i32
    scf.if %29 {
      %30 = arith.cmpi ne, %17, %c-100_i32 : i32
      %31 = scf.if %30 -> (f32) {
        %32 = tt.addptr %5, %17 : !tt.ptr<bf16>, i32
        %33 = tt.load %32 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : bf16
        %34 = arith.extf %33 : bf16 to f32
        %35 = arith.mulf %34, %cst_1 : f32
        scf.yield %35 : f32
      } else {
        scf.yield %cst_0 : f32
      }
      tt.store %6, %31 {cache = 1 : i32, evict = 1 : i32} : f32
    }
    tt.store %9, %28 {cache = 1 : i32, evict = 1 : i32} : f32
    tt.return
  }
}
